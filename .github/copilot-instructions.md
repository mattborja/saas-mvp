# Copilot Instructions

## Repo orientation
- Workshop builds a multi-tenant serverless SaaS app incrementally across labs. Each lab folder (Lab1–Lab6) has `client/` (Angular 14) and `server/` (AWS SAM, Python) plus `scripts/` for deployment. `Solution/` mirrors completed references per lab. Lab7 focuses on cost/usage.
- Server stacks use SAM templates with Lambda + API Gateway + DynamoDB; see [Lab1/server/template.yaml](Lab1/server/template.yaml) for baseline (Product/Order tables, IAM roles, Lambda functions) and later labs add multi-tenant constructs (shared vs tenant stacks in Lab3+ via `shared-template.yaml` and `tenant-template.yaml`).
- Shared Lambda layer in each server (`layers/`) provides `logger.py` (AWS Lambda Powertools logger wrapper) and `utils.py` (CORS-enabled JSON responses). Handlers call DAL modules (e.g., [Lab1/server/ProductService/product_service_dal.py](Lab1/server/ProductService/product_service_dal.py)) for DynamoDB access.

## Coding conventions
- Python Lambdas target `python3.9`, expect Powertools logger via `logger.info()`/`logger.error()` and responses via `utils.generate_response()` or `utils.create_success_response()`. Preserve Decimal handling when parsing JSON bodies in handlers.
- Environment variables and table names are injected from SAM template; prefer reading from env instead of hardcoding in code changes.
- Keep CORS headers consistent with `utils.py`. If adding handlers, reuse the layer helpers and match existing response shapes.
- IAM roles are explicitly defined in templates; when adding permissions, extend the role policy blocks rather than creating ad-hoc policies.
- API definitions live in the SAM templates; wire new Lambda functions via `Events` there rather than manual API Gateway edits.

## Build and deploy workflows
- Primary workflow: run `LabN/scripts/deployment.sh` with flags (`-s` server, `-c` client, `--stack-name <name>`). Script validates Python with `pylint -E`, ensures/creates the SAM S3 bucket, then runs `sam build -t template.yaml --use-container` and `sam deploy --config-file samconfig.toml --stack-name <name>`. Client deploy configures Angular environment files from CloudFormation outputs before `npm install && npm run build` and `aws s3 sync`.
- Lab3+ have two stacks; deploy shared then tenant: `sam build -t shared-template.yaml --use-container && sam deploy --config-file shared-samconfig.toml`, then the same for `tenant-template.yaml` with `tenant-samconfig.toml`.
- Automation script [scripts/run_workshop.sh](scripts/run_workshop.sh) chains labs and applies patch scripts (`lab*_updates.py`). Use as reference for sequencing; assumes AWS CLI is configured.

## Project-specific tips
- DynamoDB table names are suffixed per lab (e.g., `Product-Lab1`, `Order-Lab1`); keep naming consistent if cloning resources.
- CloudWatch Lambda Insights layer is attached globally in templates; keep it when adding functions to retain observability parity.
- Angular clients use environment files generated by deployment script; avoid committing manual endpoint values—let the script write them from stack outputs (`APIGatewayURL`, `AppBucket`, etc.).
- Reference completed implementations in `Solution/` when unsure about intended behavior or template structure for later labs.

## What to read first
- [README.md](README.md) for workshop goals.
- Per-lab server template ([Lab1/server/template.yaml](Lab1/server/template.yaml) or the shared/tenant templates in Lab3+) to see resources and API wiring.
- Handler + DAL pairs such as [Lab1/server/ProductService/product_service.py](Lab1/server/ProductService/product_service.py) and [Lab1/server/ProductService/product_service_dal.py](Lab1/server/ProductService/product_service_dal.py) to follow logging, request parsing, and DynamoDB access patterns.
- Deployment helper [Lab1/scripts/deployment.sh](Lab1/scripts/deployment.sh) for the expected build/deploy flow and required AWS resources.
